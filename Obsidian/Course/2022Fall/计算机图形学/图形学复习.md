## 不太清楚的基本概念
- Shading：决定屏幕上每个像素的颜色（需要考虑物体的颜色、光照情况和摄像机的位置）
- Normalized Device coordinates（NDC）：标准化设备坐标，范围为-1到1，原点为显示设备的中心
- view volume：视景体，分为正交视景体和透视视景体，opengl中，视景体使用glOrtho或者glPerspective定义，定义的坐标空间在camera space![[Pasted image 20230215170541.png]]
	- view frustum（平截头体）：perspective projection中使用的视景体
- viewport：视口，定义视景体中的内容将会显示在哪一块屏幕区域上，使用glViewport定义，定义的空间是screen space
	- 应当在投射到视景体的过程中确保view volume的可视范围长宽比与viewport的长宽比相同，否则物体形状会发生畸变
- world space中，xy平面的原点位于屏幕中心，z轴正方向指向屏幕外。camera的默认位置位于world space的原点，朝向z轴负方向
- Topology vs Geometry：没有必然关系，两个物体其中一个相同，另一个不一定相同
	- Topology：只关注顶点之间的连线关系，忽略顶点的空间位置，不受弹性形变的影响
	- Geometry：描述的是物体在空间中每一个顶点精确的位置信息、顶点之间连线的长度、图形的大小尺寸等
- Virtual Camera vs Real Camera：虚拟相机不等同于真实的相机，虚拟相机不会模拟镜片的折射等真实相机具有的物理性质
## pipeline
- graphics pipeline：也被称为渲染管线，是图形学中将一个三维物体渲染成屏幕上的一张二维图像的流程![[Pasted image 20230215174341.png]]
	- Vertex Processing：**Vertex shader（顶点着色器）** 和**Geometry shader（几何着色器）**，**生成prmitive**（图元，分为点、线、三角形、一些曲线和平面），在顶点着色器中，会进行viewing中的各种变化，图像将会被转化到screen space
	- Rasterization：图元经过**clipping and culling（裁切）** 之后，进行**Rasterization（光栅化）**，将顶点数据转换为**Fragments**（片元，每个片元对应帧缓冲区中的一像素）
	- Fragment Processing：Fragments经过**Fragment shader（片段着色器）**，在这一步中会确定每个像素的颜色，会考虑物体表面的**纹理（Texture）**
	- Blending：经过Fragment shader之后，进行**测试和混合（Test and Blending）**，生成屏幕上的**Pixel（像素）**
	- 将像素插入到屏幕帧缓冲区中，等待显示
- Vertex Shader：
	- 进行Model（world space）、View（camara space）、projection（screen space）变化。将物体从object space转化到NDC（标准屏幕空间）
	- 光照（ligthing）、法线（normal）、颜色这些每个顶点都具有的属性将在本阶段确定
- Fragment shader：
	- 计算每个fragment（或者 pixel）的颜色
- **Programmable（可编程）**：可编程的渲染流水线，在开发过程中我们可以控制渲染的每一个流程，对vertex、geometry、fragment进行自定义，充分利用现在GPU的能力，给了开发者高度的自由以实现自己想要达到的效果。
	- 与可编程渲染管线相对的是早期的固定功能渲染管线（Fixed Functioning Graphics Pipelines），其特点为固定了许多接口函数，使用者可以直接调用对应的函数进行简单的图形绘制与渲染。没有配套函数接口的效果开发者无法实现。
- **Vertex vs Primitive vs Fragment**
	- Vertex：空间中的一个点，具有自己的一些属性，属性包括**color、normal、 texture、coordinate**等
	- primitive：在渲染过程中，图元用于表示基本的几何形状，由多个vertex组合形成。可以是点、线、三角形或者多面体
	- Fragment：rasterization阶段的输出，包含了可以用于确定地显示帧缓冲区中一个像素的必要信息，包括**颜色、深度（depth）、纹理坐标（texture coordinate）、法线**等
		- 注意fragment和vertex具有的属性的差别
	- 以上三者谁对系统帧速率（framerate）影响最大需要具体系统具体分析，系统的瓶颈所在就是对framerate影响最大的。（依据具体流水线分析具体的瓶颈）
- **Graphics pipeline vs Ray-tracing**
	- Ray-tracing：可以递归实现，需要规定递归的最大深度
		- 流程
			- 如果光线（ray）碰撞到了某个物体，需要判断这个物体是否处于阴影中，从碰撞点向光源方向发射“shadow ray”
				- 如果回到光源之前碰撞到了其他物体，说明物体处在其他物体的阴影中
				- 如果首先接触了光源，说明物体被光直接照射
			- Ray与object相交会产生reflected ray，以同样的方式与其他所有的物体测试是否相交
				- 如果反射光线碰撞到了其他物体，在只考虑一次反射的情况下（也可以考虑多次反射，再次递归地产生反射光线），在被反射光线接触到的物体表面应用local illumination model（比如Phong model），并将结果传回反射光线的发出点（第一个光线与物体的交点）
			- 如果物体透明，会产生transmitted ray（折射光），同样的方法递归处理折射光
		- Ray-tracing的处理过程可以递归地生成一棵树（Ray tree），通常，物体会被包含在一个简单的立体图形中（BVH），需要维护一个BVH树，使BVH树尽可能平衡
		- 对于散射光（scttering rays），采用蒙特卡洛方法采样
	- Pros：光追能更真实地模拟光线，并且不需要像流水线方法一样设置深度缓冲区。可以实现软阴影、多重反射、粗糙平面的反射等真实效果，pipeline难以实现。
	- Cons：不是所有的光线都对视觉具有明显的作用。采用光线追踪需要消耗大量的算力，光线与物体求交等操作需要复杂的计算和算法。相较于pipeline更加难以实现。
## Viewing
- Viewing：![[Pasted image 20230215165648.png]]
	- Transform into camera coordinates：先转化到世界坐标（model矩阵），再转化到相机坐标（view矩阵）。使用glm中的各种转化完成
	- perform projection into view volume：进行projection（投影），注意，投影之后坐标还是在4维齐次坐标系下。
	- 在clipping space中进行clipping，裁掉规范化视景体（canonical view volume）之外的几何形状
	- 透视除法，从clipping space（四维齐次坐标系）变化回三维空间的NDC坐标 **（NDC坐标也是三维的）
	- 进行Final projection，去除z轴，处理深度问题，转化到screen space（视口中的2维坐标）
- global空间上的变化与local空间上的变化，顺序相反，采用以下方式证明：![[Pasted image 20230217174424.png]]
	- 世界坐标系下：先平移，之后相对于物体中心旋转，因为世界坐标系下只能相对于世界坐标系的原点旋转，因此要先移动回来，旋转完再移过去。整体上看，相当于先旋转再移动
	- 局部坐标系下：平移后旋转相对于局部坐标系的中心，因此是先平移再旋转
- Projection：
	- Orthographic projection（正则投影）
		- 保留形状，常用在工程领域（CAD、说明书、建筑物结构图）
		- 不能看到物体真实的形状，很多表面被遮挡
	- Perspective projection（透视投影）
		- 看起来真实
		- 角度、长度会随着视角发生改变
- **What coordinate spaces are involved in viewing?
	- object space
	- world space
	- screen space
- Homogenous Coordinates（齐次坐标系）：
	- 为向量增加一个新的维度w（齐次项），一般**加入时使w等于1
	- 齐次坐标系转化回笛卡尔坐标系：
		- 假设齐次项不为0，如果**齐次项不等于1，那么向量的所有位都要除以齐次项w**，然后取向量中除了齐次项之外的其他位，就是笛卡尔坐标系中的坐标
	-  好处：齐次坐标系下，各种变化可以用一个矩阵表示，方便多个变化的结合
- **Transforms** in Viewing：除了需要处理深度信息的viewport transform，所有的变换都属于projective（映射）![[Pasted image 20230216170921.png]]
	- Affine Transform：仿射变换
		- 定义：一个线性变化和一次平移的组合（向量左乘一个矩阵（线性变换），再加上一个向量（平移）
		- Similitudes Transform：
			- 不会改变几何形状上线与线之间的位置关系（可以理解为允许存在角度、大小的变化，但物体看起来和之前相同）
			- Rigid/Euclidean Transform：欧几里得变换
				- 定义：仅包含平移和旋转（绕一个确定的轴）
				- **Translation Transform：平移变换
					- 直角坐标系下：加上一个向量![[Pasted image 20230216174608.png]]
				- **（Identity）Rotation Transform：旋转变换
					- 规定$\theta$是围绕坐标系原点逆时针旋转的角度
					- 二维情况：旋转以某个确定的点为中心![[Pasted image 20230217154101.png]]   ![[Pasted image 20230217154421.png]]
						- 旋转矩阵如下：![[Pasted image 20230217154454.png]]
					- 三维情况下：旋转以某个确定的直线作为转轴
						- 欧拉角：将三维旋转分解成分别绕x、y、z轴进行的三次旋转
							- 绕x轴：![[Pasted image 20230217170824.png]]
							- 绕y轴：![[Pasted image 20230217171337.png]]
							- 绕z轴：![[Pasted image 20230217170803.png]]
							- Gimbal Lock（万向节锁）：当某个角度的变化为pi/2时，会产生歧义
						- 四元数+轴角：可以平滑地转动，解决万向节锁的问题
		- **Isotropic Scaling（Uniform Scaling）：各向同性缩放变换
			- 各个轴上缩放尺度相同，是各向异性旋转的一个特例
		- **Ortho Projection：正则投影
		- **Scaling Transform：各项异性缩放变换
			- 各个轴上缩放尺度不同
			- 直角坐标系下：$M=diag(sx,sy,sz)$，sx、sy、sz分别为x、y、z轴方向上的放缩倍率
		- **Reflection Transform：镜像变换（相对于坐标轴）![[Pasted image 20230216182002.png]]
			- 直角坐标系下：$M=diag(s1,s2,s3)$，s1、s2、s3可以是1或者-1，当值为-1时，分别表示关于x、y、z轴垂直的平面镜像。多个-1，可以拆分成依次进行多次镜像的组合
			- 二维下是一个2x2的对角阵，对角线元素分别表示关于y、x轴镜像
		- **Shear Transform：切变变换![[Pasted image 20230216182038.png]]
			- 直角坐标系下：可以用一个对角线上元素全部为1的矩阵表示（没有放缩），其余元素任意
	- Linear  Transform：线性变换
		- 性质：![[Pasted image 20230216182439.png]]
		- 可以用一个**与向量同尺度（n维向量对应n\*n）** 的方阵表示的变换
		- Affine Transform中除了Translation之外的全部变换都属于Linear Transform
	- **Perspective Projection：透视投影
- 假设向量v原来的维数为n，转化为齐次坐标系后（最后加一位1作为齐次项），位数为n+1，变化之后的向量转化回笛卡尔坐标系的结果为$v1$。那么在齐次坐标系中，各个变换具有如下的特点：
	- 仿射变化，变化的矩阵如下图所示：![[Pasted image 20230216180157.png]]
		- $v'=[0,0,...,0]$
		- 平移变化：$M'=E^{n}$，$v1=v+v_t$
		- 线性变化：$M'$与笛卡尔坐标系下的变化矩阵相同（$v1=M'v$），$v_t=[0,0,...,0]$
		- 总结：$M'$表示线性变化成分，$v_t$表示平移变化成分，它们的数值都和笛卡尔坐标系下的数值相同
	- 非仿射变化：最后一行不一定有$v'=[0,0,...,0]$，且最后一位不一定为1
- Virtual Camera：
	- Default：
		- 相机位置：位于原点，朝向Z轴负方向
		- 视井体：一个边长为2的正方体![[Pasted image 20230227201932.png]]
	- 移动相机：我们无法移动virtual camera，因为虚拟相机实际上并不存在，我们使用**将物体向反方向移动来替代移动相机
		- 使用ModelView Matrix，移动相机和物体（实际上都是在移动物体），来将物体从objecy space投射到world space，再投射到camera space
	- opengl中的实现：![[Pasted image 20230227202955.png]]
		- 注意：相机在相机空间中朝向z轴的负方向，只是物体在投射到camera space后的坐标改变了
```cpp
glm::LookAt(eye,center,up);
// eye：定义相机的位置
// center：定义画面的中心
// UP：朝向上方的向量，确定相机的角度
```
- **Projection Transformation（透视变换）：
	- 在model、viewing transformation之后，所有的物体在世界空间中的坐标已经确定，并且和我们最后看到的对应
	- Normalization：实现中，不是对每种投影都分配不同的投影矩阵，而是将这些不同的投影全部转化为具有标准视景体的正则投影（NDC）
		- 想象一个真实存在的视景体，以上过程**相当于将视景体转化为边长为2的正方体，并且移动到原点
		- 注意：NDC中，z轴朝向屏幕内部，而在未规范化的视景体中，z朝向外，因此是near-far，因此最后w为-z，将坐标轴反过来
	- **orthographic projection（正则投影）：
		- 视景体：![[Pasted image 20230227203419.png]]
		- 正则投影矩阵：
			- 将center移动到原点$T(-(left+righ)/2,-(bottom+top/2),(near+far)/2)$
			- 将边长变化为2（Scale，为了表示长度，都是大的减小的，由于相机朝向z轴负方向，因此near一定大于far）$S(2/(right-left),2/(top-bottom),2/(near-far))$
			- 最后的矩阵（是一个仿射变换）：![[Pasted image 20230227210509.png]]
		- 最后的投影（viewport projection）：
			- 去掉深度信息，z=0，等价于以下的齐次变换![[Pasted image 20230227210645.png]]
	- **Perspective projection（透视投影）：
		- 简单的投影：投影的中心在原点（相当于eye的位置），投影到平面z=d上，其中d<0（相机对着z轴负方向）![[Pasted image 20230227211449.png]]
			- 可以发现：x、y坐标，随着深度z变大都会缩小，符合近大远小的透视特点
			- 以上的简单投影，在齐次坐标系下的表示：![[Pasted image 20230228160832.png]]
				- 对产生的坐标齐次化，这个过程也叫**透视除法**，使x、y坐标变得近大远小
		- **透视变换
			- 理解：本质上也就是把四棱台形状的视景体（假设其存在），变化为标准视景体（NDC）![[Pasted image 20230228162009.png]]
			- 首先，由于目标投影平面是z=-n，因此进行投影也就是将xe、ye、ze等比例变换，使zp=-n![[Pasted image 20230228162245.png]]
			- 接下来，需要将xp和yp进行Normalize，类似于正则投影一样，将其进行平移和缩放，再加上透视除法，最后变成NDC![[Pasted image 20230228162957.png]]
			- 最后的矩阵如下，产生的坐标最后一维为-z，刚好满足透视除法的需求，投影矩阵产生的是还没有normalize后的结果（clipping space），以上过程只是用于推导![[Pasted image 20230228163403.png]]
			- 现在我们已经解决了与X、Y坐标有关的平移和缩放问题，现在留下的问题是：z坐标需要怎样变换？
			- **可以确定，z坐标一定与x、y坐标无关，只和透视投影的目标平面有关**，因此我们可以假设以下的投影矩阵：![[Pasted image 20230228163702.png]]
			- 结合我们的已知信息，可以解出A、B，将ze和zn两组带入方程![[Pasted image 20230228165602.png]]
			- 最后的透视投影矩阵：需要注意，这个矩阵将物体从camera space转化到了clipping space，还没有进行透视除法![[Pasted image 20230228165703.png]]
- clipping：
	- When to clipping？
		- 在投影变换之前：需要解决与平面和直线的相交问题，虽然很自然，但难以实现
		- **在四维齐次clipping space中**（也就是在projection变化之后，在进行透视除法转化到NDC之前）：最容易实现，也是实际上采用的方法
		- 在NDC中，透视除法之后：会存在问题
			- 当物体的z坐标小于等于相机位置的z坐标时，会出现问题，无法正常显示![[Pasted image 20230228185141.png]]
	- why to clipping？
		- 防止透视除法中出现除以0的情况
		- 防止相机背后（z小于相机）的物体被看到
	- clipping lines：
		- 直观的方法：计算线段和平面/直线的相交，去除以外的部分（运算困难）
		- Cohen-Sutherland Algorithm
			- 将空间分为9个格子，中间的格子代表处于视景体中的格子
			- 为每个线段的两个顶点计算一个编号（outcode），计算规则如下：![[Pasted image 20230228190458.png]]
				- 注意：位于边缘上，对应的那一位都当成0
			- 对一个线段的两个顶点，分别计算outcode，并分类讨论：![[Pasted image 20230228190627.png]]
				- AB：两个顶点的endcode相同且都等于0000
					- 说明两个顶点都在clipping window中，这线段全部保留
				- CD：一个顶点的endcode为0000，另一个不是
					- 找出D的endcode，其中的每一位1，代表了需要将CD和一条不同的直线计算相交，假设交点是D‘，保留CD’
					- 如果D有两位是1，需要和两条直线计算相交，假设交点分别是D‘和D’‘，检查这两个交点的outcode，取其中为0000的那一个，保留它和C之间的连线
				- EF：两个点的endcode都不是0000，且相等
					- 抛弃这条线段
				- GH：两个顶点的endcode都不是0000，且只有一位不相等
					- 抛弃这条线段
				- IJ：两个顶点的endcode都不是0000，且有两位不想等
					- 缩短线段：首先通过I、J不想等的两位确定两条直线，**任意选择一条，计算IJ和它的交点**，检查交点的endcode
						- 假设为0000，使用交点和距离交点较远的那个顶点之间的线段代替原来的线段，转化为CD情况
						- 假设不是0000，抛弃这条直线
			- 此算法对任意图元和任意维度都适用![[Pasted image 20230228191939.png]]
				- 3D的情形：可能需要计算和平面的相交![[Pasted image 20230228192035.png]]
			- 评价：存在很多情况不需要计算相交，减少了计算量，但需要缩短线段的情况需要执行两次算法。
	- clipping polygon：
		- 基本方法：计算所有交点并连接，难以实现且效率很低![[Pasted image 20230228192856.png]]
		- Weiler-Atherton Clipping：
			- 方法：
				- 计算所有交点
				- 将所有多边形进入clipping window的交点标记出来（下图中表示为绿色）![[Pasted image 20230228193643.png]]
					- 将多边形的每条边都表示成向量，每个向量指向相邻向量的起点，最后标记所有指向clipping window内的向量和边缘的交点，整个多边形应该是逆时针旋转
					- 如果一个向量和两条边相交，第一个点标记，第二个点不标记
					- 两个相邻的顶点肯定一个in一个out
				- 选取任意一个in交点开始，记录这个顶点和它的相邻顶点分别为v1、v2，讨论v1和v2:![[Pasted image 20230228194310.png]]
				- 继续讨论相邻的下一对交点，能形成闭合多边形时，优先形成闭合多边形，之后就不用再考虑已经用于形成闭合多边形的交点了![[Pasted image 20230228194446.png]]
				- 继续执行，直到所有的交点都用于形成多边形了
			- 讨论：
				- 鲁棒性：顶点在边上、非常接近边的时候，由于浮点精度问题可能导致错误
		- 转化为三角形：
			- 先将多边形分割为多个三角形（三角形本身一定是凸多边形）![[Pasted image 20230228195145.png]]
			- 对每个三角形进行clipping方法使用接下来介绍的Sutherland-Hodgman Polygon Clipping![[Pasted image 20230228195217.png]]
		- Sutherland-Hodgman Polygon Clipping（针对于凸多边形）：
			- 思想：对clipping每条边上发生的clipping，与其他变独立，可以分别处理（用四个独立的clipper），以流水线方式实现![[Pasted image 20230228195518.png]]
			- 方法：
				- 类似的方法将多边形每条边表示成向量，对多边形每条线段上的两个顶点，计算它俩是否在clipping window中，分为以下四种情况讨论（只有从外向内输出两个点）：
					- out->in：输出交点和在clipping window内的点（终点）                 ![[Pasted image 20230228195651.png]]
					- in-> in：输出终点![[Pasted image 20230228200008.png]]
					- in->out：只输出交点![[Pasted image 20230228200037.png]]
					- out -> out：不输出![[Pasted image 20230228200123.png]]
				- 依次对各个边操作，把所有产生的点依次连接起来即可
				- 流水线方法中，每次只对一条边对应的直线进行以上操作，在和clipping window在直线同一侧为in，否则为out，下面就是right clipper![[Pasted image 20230228200425.png]]
					- 四个clipper分别进行，流水线操作，三维中添加两个clipper（front 和 back即可）![[Pasted image 20230228200520.png]]
	- clipping之后，使用透视除法转化到NDC
- Visible Surface Detection：
	- Painter‘s Algorithm：
		- 思想：按照从后向前的顺序渲染多边形，这样深度浅的多边形会覆盖之前的，就看不见后面的表面了，要实现Painter‘s Algorithm，首先需要对深度进行排序
		- Depth Sort：
			- Binary Space Partitioning Tree（BSP Tree）的建立
				- 例子：从上向下看，多个多边形都只是一条线，BSP 算法在此基础上进行![[Pasted image 20230228224148.png]]
				- 随便选择一个多边形，沿着它将scene分成两半，分别为front 和 back子空间，如果一个多边形被分割线穿过，则将其分为两部分![[Pasted image 20230228224619.png]]
					- 被用作分割的多边形的法线指向的半部分为front half-space
					- 被选中来分割空间的多边形位于中间节点，之后的分割不再影响该多边形
				- 从front space和back space中再选择多边形一个用于分割
				- 重复以上操作直到每个节点中都只有一个多边形为止![[Pasted image 20230228224716.png]]
			- BSP建立完成之后，对于任何一个视角，都可以通过遍历BSP树来确定该位置的深度顺序![[Pasted image 20230228225722.png]]
				- 假如在front space，右->中->左顺序遍历BSP
				- 假如在back space，左->中->右顺序遍历BSP
			- 评价：建立BSP开销很大，但一旦建立之后，无论从什么视角观察都可以很快渲染，适合用在场景中object的位置不经常改变的情形中
	- Z-buffering（depth buffer）
		- 图像空间的方法，因为维持Z-sort的代价太过于昂贵
		- 基本的思想：
			- 对所有的polygon进行光栅化
			- 对polygon内每个像素，通过插值计算其深度信息
			- 对每个像素，采用深度值最小的多边形的颜色
			- 使用距离观察位置最近的polygon的颜色画出对应的像素，可以以任何顺序绘制多边形，只需要保持对z最小多边形的颜色保持即可
		- 例子：
			- 首先在NDC空间中，初始化Z-buffer，max-z=1![[Pasted image 20230228230833.png]]
			- 先画蓝色多边形，填充depth buffer![[Pasted image 20230228230926.png]]
			- 再画黄色buffer，对于buffer中的一个像素，如果新绘制的深度更小，就覆盖之前的结果（颜色和深度值都覆盖）![[Pasted image 20230228231129.png]]
			- 在不断更新z-buffer的过程中保持以上原则
		- 评价：
			- 优点：硬件容易实现，消耗空间少，对于复杂的空间和多边形都适用，不需要计算物体与物体之间的相交
			- 缺点：
				- 需要额外的存储空间、hidden objetc也要绘制，浪费时间
				- z-precision errors（z-fighting）：由透视除法产生，互相靠近的像素z的值过于接近（浮点数精度问题），导致可能无法正确地显示。![[Pasted image 20230302144453.png]]
					- 解决：不能让透视中的near plane太近，far plane 太远
## Rendering
- Rasterization
	- 定义：Converting a continuous objrct such as a line or a circle into discrete pixels
		- First job :找出图元覆盖的所有像素
		- Second job :使用各个顶点进行内插（interpolate），确定像素的各种属性数值
	- Rasterize Points：![[Pasted image 20230301155502.png]]
		- point的中心在像素内：覆盖这个像素
		- point的中心在像素边缘：保留左上，丢弃右下
	- Rasterize Lines and Circles：
		- naive method：第一象限x=y以下的部分![[Pasted image 20230301155727.png]]
			- x每次向右移动一位，加一，依据斜率计算对应y的数值
		- DDA（Digital Difference Analyzer）：
			- 以上方法的改进，使用迭代的方法计算每一次x、y的变化
			- 方法：![[Pasted image 20230301160241.png]]
				- 假设斜率m<=1，每次x移动一格（x加1），y增加m
				- 假设斜率m>1，采用对称的思想，将x、y对换即可
			- 缺点：浮点运算时间长（计算斜率m）、每次需要取整
		- Bresenham‘s Algorithm：
			- 针对第一象限m<=1的部分进行讨论，其他部分采用对称的方法即可
			- 方法（处理直线）：
				- 一个点确定后，下一个点x一定会加一，y可能加一也可能不变![[Pasted image 20230301160718.png]]
				- 因此，关键是计算出直线上的这一点到上下两个像素的中心哪一个更近，也就是计算如下的b-a，并且将$\Delta x$、$\Delta y$分离出来![[Pasted image 20230301162929.png]]
				- 继续观察可以发现：d也是可以递推的，并且dk的正负决定了下一个点yk是否需要加一。并且d0可以用y0替代dk得到![[Pasted image 20230301163200.png]]
				- 总体算法如下：![[Pasted image 20230301163238.png]]
		- Midpoint Algorithm：思想类似于Bresenham
			- 方法（处理圆）：
				- 只需要在第一象限的上半部分分析，其他部分对称即可![[Pasted image 20230301163358.png]]
			- 计算下一个中点是否在圆内，dk<0，说明在圆内y_{k+1}=y_k，否则y_{k+1}=y_k-1![[Pasted image 20230301164258.png]]
			- dk的递推公式![[Pasted image 20230301164419.png]]
	- Rasterize Polygons：
		- 通常的想法：算出所有位于多边形里面的像素，关键在于如何判断像素是否位于多边形内部
		- 处理三角形：
			- 同时光栅化三角形的两条边（垂直方向上进行），并且水平填充每次产生的两个像素之间的像素![[Pasted image 20230301165228.png]]
			- 假设出现以下情况，需要将三角形分割为上下两部分![[Pasted image 20230301165326.png]]
		- 任意多边形：
			- Flood Fill：将多边形的边缘提前标记出来（标记为黑色），可以使用此方法递归地填充多边形![[Pasted image 20230301165703.png]]
			- Triangulation（三角化）：
				- 将多边形分割为多个三角形，三角形的光栅化速度非常快
				- Ear-clipping![[Pasted image 20230301165820.png]]
				- Seidel‘s Algorithm：![[Pasted image 20230301165910.png]]
	- Interpolation of attributes（属性内插）：
		- 在Rasterization的过程中，不仅仅要选择像素，还要通过内插确定每个像素上的属性信息（Depth、Color、Texture Coords等）
		- Linear interpolation：2D的线段可以使用DDA进行插值
		- Interpolation for Triangles（Bilinear Interpolation，双线性内插）：类似于三角形的光栅化，先插值确定扫描线的端点，再用两个端点为内部像素插值![[Pasted image 20230301172456.png]]
	- Antialiasing（抗混叠）
		- Aliasing：线段考得太近，高频信息不符合采样定律，发生混叠
		- 抗混叠：使用subpixels（子像素），具体方法有box filtering和Weighted Filtering![[Pasted image 20230301172747.png]] ![[Pasted image 20230301172804.png]]
- Illumination models and Shading
	- Illumination model
		- Global illumination model：
			- 模拟直接光照和间接光照，可以产生反射、折射、阴影，消耗更大的计算量（代表方法：Ray-tracing）
		- Local Illumination model：
			- 只考虑光源和物体表面的性质，运算速度快，效果接近于GI model
	- Light sources：
		- Point light（点光源）
		- Directional Light（平行光）
		- Spotlight
	- 常见的Local illumination model：
		- Phong reflection model：
			- 输入：matrial的性质，I，n，v（所有向量都是从物体上发出的）![[Pasted image 20230301174304.png]]
				- matrial属性：matrial产生3种光的强度有所不同，由ka、kd、ks分别控制产生ambient、diffuse、specular 反射的强度，shininess等于alpha，用于控制产生specular 反射的强度
			- 计算：
				- 对于单独的光源![[Pasted image 20230301181100.png]]
					- 分别计算Ia、Id、Is，并求和
					- La、Ld、Ls分别为光源产生环境光、散射光、镜面反射光的强度
				- 多光源![[Pasted image 20230301181228.png]]
					- 环境光Ia只计算一次，而Id、Is需要进行求和
				- 考虑衰减：Ia不衰减，Id和Is随着距离衰减（经验模型）![[Pasted image 20230301181453.png]]
				- 实际上的衰减，对于不同光源有所不同
					- directional light：Ia、Id、Is均不需要衰减
					- point light：三个都按照上述比例衰减
					- spotlight：Ia按上述比例衰减，Id、Is需要额外考虑是否在spotlight能照射到的范围内，如果不在直接为0（计算angAttenuation）
		- Blinn-Phong reflection model
			- 一种对Phong refelction model的修正，修改了计算Is的方法![[Pasted image 20230301181753.png]]
		- Why blinn-phong is better than phong？
			- blinn phong采用半程向量H计算反射高光，取代了r（反射向量），计算r向量需要更高的计算量，并且采用blinn phong模型产生的高光更加柔和
	- Surface Shading：shading model和reflection model不同，但可能采用类似的思想（smooth shading都采用了Phong reflection model）
		- Flat Shading：每个三角形（polygon）采用一种颜色，不连续的shading，对光滑表面不适用
		- Smooth Shading：
			- Gourand Shading：一种内插方法
				- 方法：
					- Normal averaging（法线平均）：用一个顶点周围顶点的法线，计算平均值，作为这个顶点的法线![[Pasted image 20230301183804.png]]
					- Vertex lighting：适用blinn phong reflection model，计算每个顶点的颜色信息![[Pasted image 20230301183941.png]]
					- 使用双线性内插，算出每个像素的颜色信息![[Pasted image 20230301184121.png]]
				- 缺点：对高光的表现不佳
			- Phong Shading：和之前的Phong reflection model不是一个人，也是一种内插方法
				- 与Gourand Shading不同，Phong Shading直接内插法线，然后在每个像素上使用reflection model和内插出的法线计算像素的颜色![[Pasted image 20230301184340.png]]
				- 优点：高光表现好
				- 缺点：每个像素都需要计算反射模型，计算消耗更大并且在固定的流水线中难以实现
- Texture Mapping：
	- Texture vs Material![[Pasted image 20230301191658.png]]
	- Texture mapping：将一张“image”（texture map）使用UV坐标投射都一个3D模型上，texture map上的每个像素（pixel）变化到UV坐标后对应一个纹素（texel）
		- where to texture mapping：在进行clipping之后，rasterization阶段进行，不需要考虑已经被裁切的ploygon
	- UV mapping：![[Pasted image 20230301192838.png]]
		- UV Interpolation（UV内插）
			- pixel coordinates to UV coordinates（2D to 2D），但UV坐标不能线性内插到屏幕空间
				- Problem：Perspective distortion（透视失真）：深度信息不同，2维平面线形内插到3维空间中，没有考虑到对深度信息的处理![[Pasted image 20230301193015.png]]
			- Perspective correction（透视修正）：uv坐标也应该除以深度信息，可以在齐次坐标系下进行解决![[Pasted image 20230301193244.png]]
			- Aliasing of textures（纹理混叠）：多个纹素（texel）覆盖在一个像素上，通常出现在距离较远或者纹理表面被过于放大的情况![[Pasted image 20230301193539.png]]
	- Mipmapping：
		- 方法：使用不同分辨率（一般设置几个分辨率级别）的texture，依据一个texel上对应的pixel数量（计算Mipmapping level），选择不同分辨率的texture![[Pasted image 20230302135804.png]]
			- 在UV空间中，计算两个像素之间的最小距离，用于判断mipmapping level
		- 问题：如果总是使用最接近的mipmapping level，会导致相邻的位置出现分辨率等级的“跳跃”
			- Trilinear Filtering：三线形滤波器，在level之间内插
	- Bump-mapping：
		- 方法：将texture 看作一个hight function，使用其局部的变化来计算模型表面的法线（normal），能具有更加真实的凹凸效果
	- Displacement mapping：
		- 方法：使用texture map来移动模型表面的点（之前的方法都没有对模型表面点的坐标进行任何修改），也可以体现出更真实的凹凸效果![[Pasted image 20230301194826.png]]
	- Cubic mapping：
		- 使用方体texture map，将2维 UV坐标转化成3维的texture direction，一般用在天空盒等模型为方体的情况中![[Pasted image 20230301195113.png]]
	- Environment mapping：
		- 方法：使用周围环境的物体计算出正确的纹理，用来表现反射效果
- Physically-based Rendering（PBR）：
	- Radiant energy：撞击到屏幕上的光子（photons）所具有的全部能量
	- Rediant flux（辐射通量）：Radiant energy对时间求导![[Pasted image 20230301200501.png]]
	- Irradiance（辐照度）：Rediant flux对面积求导，表示单位区域上、单位时间中的总能量![[Pasted image 20230301200631.png]]
	- 固体角（Solid Angle）：一个球面上的一块区域所对应的角度![[Pasted image 20230301201207.png]]
		- 微分形式：![[Pasted image 20230301201246.png]]
	- Radiance：
		- 定义：单位固体角上的辐照度（Irradiance）![[Pasted image 20230301201618.png]]
		- 性质：
			- 与一束光直接相关，沿着一束光的方向，在它没有衰减的情况下（真空中），Radiance处处相等
			- 使用PBR进行渲染实际上就是对Radiance的计算
	- Render Equation：计算某一点发射出的Radiance和反射/散射的Radiance，采用积分方法，描述模型上某一点在某个方向上发出的能量（radiance ）总和![[Pasted image 20230301203006.png]]
		- 双向反射分布函数（Bidirectional reflectance distribution function BRDF）:表示物体表面反射方向上的辐射亮度增量与入射方向辐射照度增量的比率![[Pasted image 20230301203415.png]]![[Pasted image 20230301203116.png]]
		- 不同反射情况下，BRDF计算结果有所不同
		- 类似的有双向折射分布函数（BTDF）
	- Render Equation的实现：使用蒙特卡洛方法近似积分的结果，从某种分布中，使用蒙特卡洛方法对omiga_i（体积角，表示方向）进行采样![[Pasted image 20230301210137.png]]
- Shadows：
	- Ground Shadows![[Pasted image 20230301205501.png]]
		- 原理：先画出产生影子的物体，然后使用一个矩阵，将物体移动到地面上，然后用灰色将这个物体重新画一遍（以下矩阵可以将物体转移到地面）![[Pasted image 20230301205440.png]]
		- 问题：
			- hard shadow（硬阴影）
			- 只会在地面平面上产生阴影
			- 静态场景中此方法不能进一步优化
	- Shadow Texture
		- 根据光源产生一个阴影图片作为纹理，将其投射到物体表面（可以投射到平面或者曲面上）![[Pasted image 20230301205729.png]]
	- Shadow map![[Pasted image 20230301210454.png]]
		- 准备工作：
			- 每个光线对应一个深度buffer
			- 从光源位置开始渲染场景（场景不会产生shadow）
			- 渲染过程中，将深度信息保留在光源对应的buffer中
		- Rendering：
			- 开始渲染物体，渲染到某个物体时，将其坐标转化到light space，如果转化之后它的深度数值大于光源对应的depth buffer中的数值，它就应该产生阴影
	- Shadow volume![[Pasted image 20230301210832.png]]
		- 思路：在现实生活中，一个物体在一个光源作用下产生的阴影可以看作一个具有体积的立体形状，**从光源处，向每个顶点投射一条无限长的光线，形成shadow vloume，每个处于这个几何体中的物体都应该具有阴影
	- Shadow map VS Shadow volume
		- Shadow map更快，但由于depth buffer的精度问题，没有shadow volume准确，特别是在物体的边缘容易产生混叠现象（Aliasing）
	- Soft Shadows：
		- PCF：计算复杂并且不是真正的软阴影
		- PCSS
## Geometry
- Polygon Mesh
	- 定义：representing a 2D surface embedded in R3 by using a set of polygons（用多边形表示一个embed在三维空间里的2维平面）
	- what is a valid Geometry
		- Mesh Validity：what is a valid mesh？![[Pasted image 20230301223438.png]]
			- manifold（流形）
				- edge：一条公共边最多只能被两个多边形所共有，每条边必须对应两个三角形
				- point：每个顶点必须对应一系列三角形，围绕成一个唯一的环（不能有两个没有公共边的三角形共享一个顶点）
			- maniflod with boundary
				- weaken rules to allow boudarys
				- 围绕着一个顶点的多个三角形可以组成一个不完整的环
		- Topological validity：不一定总是成立
			- front（outside）or back（inside）of a face，当看到所有顶点逆时针分布时，认为处于outside（front）
			- 所有相邻的三角形必须具有相同的“outside”![[Pasted image 20230301223924.png]]
		- Geometric Validity：实际中也很难保证
			- 通常情况下不希望有自己和自己相交的平面![[Pasted image 20230301224033.png]]
- Mesh Query：迭代访问某种类型（edge、face、vertices）的所有元素，并且每个只访问一次
	- 支持mesh query可以让渲染更加快速，同时几何体的结构可以较为方便地修改，并且在修改的同时还保持mesh的性质。在大型、可以改变的场景的渲染中需要支持mesh query
	- 需要mesh data structure以支持mesh query
- Polygon soup：存放所有的polygon，不保留公共顶点信息（比如VBO就是这种）
	- Mesh data structure：
		- Independent Triangles（用于render，难以query）：保存每个三角形三个顶点的坐标，具有冗余信息，且无法表示三角形之间的相邻关系
		- Indexed Triangle set（用于render，难以query）：每个顶点记录一次，只记录一个三角形有哪些顶点，无冗余，但还是没法表示三角形之间的邻接关系![[Pasted image 20230301225515.png]]
		- Triangel Strips（用于render，难以query）：利用了Mesh特性，使用一串顶点序列表示一系列相邻的三角形，理论上消耗存储空间最少（平均顶点的数目和能表示的三角形数目相同）![[Pasted image 20230301225706.png]]
			- Triangle Fans：采用了和Triangle Strips类似的思路
		- Winged-edge data structure（方便进行query）：可以表示邻接信息，但存在冗余
		- Half-edge structure（方便进行query）：每条边上具有两个半边![[Pasted image 20230301230523.png]]
			- 顶点存放的是终点
	- 降低LOD（level of Detail）
		- Vertex removal：需要重新对多边形三角化![[Pasted image 20230301230839.png]]
		- Edge collapse：使用半边数据结构很好实现![[Pasted image 20230301230940.png]]
			- 第一步：对边的，反方向的半边互相作为对方的新opposite![[Pasted image 20230301231034.png]]
			- 第二步：两个顶点只保留一个，修改相关半边的vertex![[Pasted image 20230301231111.png]]
- Curves and Surfaces
	- Limitation of Polygonal mesh![[Pasted image 20230301231321.png]]
	- Spline curve（样条曲线）：使用一些控制点定义曲线，移动控制点的同时会改变曲线![[Pasted image 20230301231550.png]]
		- Linear Interpolation：两个点之间最简单的“曲线”![[Pasted image 20230301231844.png]]
		- Hermite spline cureve![[Pasted image 20230301231942.png]]
			- 如何从曲线上的两个点确定a、b、c、d![[Pasted image 20230302012336.png]]
			- 解出a、b、c、d，即可解出上述的曲线
		- Bezier curves
			- 表示Bezier曲线的方法如下：
				- 从一个点开始![[Pasted image 20230301232530.png]]
				- 再加入一个控制点，表示成线性内插![[Pasted image 20230301232614.png]]
				- 再加入一个控制点P2，先和P1内插，结果和之前p0、p1内插的结果继续内插![[Pasted image 20230301233012.png]]
				- 再加入一个控制点，先和P_{3-1}=P_2内插，产生P_{1,2}，然后类似原理接着插![[Pasted image 20230301233658.png]]
				- 总结：
					- 产生在pn和pn-1之间的都是p{1,n-1}
					- 产生在p{1,n}和p{1,n-1}之间的是p{2,n-1}
					- 同理递推，最后p{n,0}是目标曲线
		- BSplines：大于4个控制点，局部满足bezier曲线，曲线本身不一定经过任何控制点
		- Subdivision Curves：
			- Corner cutting：新加入的点是之前点的线形组合![[Pasted image 20230302013706.png]]
			- For B-spline对奇数点和偶数点处理方法不同，新产生的曲线上的点是原先曲线上点的线形组合![[Pasted image 20230302014209.png]]
	- 连续性：C0、C1、C2分别为自身连续、一阶、二阶连续，其中C2性质对渲染很重要
	- curve to surface（SPline surfaces）：可以使用两个curve定义一个曲面（tensor product）![[Pasted image 20230301234805.png]]
	- Subdivision surface![[Pasted image 20230301235608.png]]
		- 基于polygon mesh，使用一定规整增加更多的顶点
		- 第一步：subdividing the mesh（计算新的topology）
		- 第二步：放置新的顶点
	- Subdivision vs Splines：
		- Splines效果更好，几乎都可以达到C1连续，从参数空间映射到3D空间实际上就是求控制点的线性组合