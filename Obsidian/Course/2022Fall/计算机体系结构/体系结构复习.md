-  Amdahl定律：6
	- 加权性能比较，评价方法为时间比值
- CPU性能公式：11
	- CPI（cycle per instruction）
	- IC：总共的指令条数
- 可移植性：32
	- 系列机：相同系统结构，不同实现方式
	- 模拟和仿真
		模拟：软件方法，宿主机上实现另一套机器的指令集（虚拟机）
		仿真：硬件方法，宿主机上的微指令解释另一机器上的指令集
	- 统一高级语言
- 计算机性能量化标准：
	- mips
	- mflops
	- 加权执行时间……
- 并行性：33
	- 处理数据角度：四种分类
	- 执行程序角度：五种级别
	- 提高并行性途径：三种途径
		- **时间重叠**：多个处理过程时间上错开
		- 资源重复：重复设置硬件资源
		- 资源共享：多个任务轮流使用一套硬件设备
- Flynn分类法：
	- SISD：单指令单数据流，每次译码一条指令，为一个部件分配数据
	- SIMD：各处理机同步执行同一指令
	- MISD：一个处理机同时执行多个指令，不实际
	- MIMD：作业、任务、指令全级别并行
- 指令集结构分类：
	- 寄存器型
	- 累加器型
	- 堆栈型
- CISC：
	- 特点：指令复杂，减少程序指令数量以提高性能
	- 优化方法：面向目标程序、面向操作系统
	- 问题：硬件复杂、规整性欠佳难以优化、复杂指令使用频率低且CPI大
- RISC：
	- 思想：简化指令功能以降低硬件设计的复杂度，以提高指令的执行速度
	- 指令条数少而简单，格式简单统一
	- load-store结构
	- 优化编译器作用
	- 使用流水技术提高性能
- 数据表示和数据结构：
	- 数据表示：硬件可识别、指令集可直接调用的数据类型，常用、简单、易于硬件实现
	- 数据结构：软件实现和处理的复杂数据类型
- 编码格式：定长、变长、混合（提供若干种固定的指令字长）
- 拓展编码法：高位需留出特定组合，预示需要更长的位数
- 优化单个地址码
	- 间址寻址（存储器低位设置专门的单元用于存放地址）
	- 变址寻址（基址寄存器+地址偏移量）
		- 考试中需要指定使用哪个寄存器作为基址寄存器
	- 寄存器间接寻址（地址存放在寄存器中）
- 流水线特点：
	- 只有连续提供同类任务才能发挥流水线效率（通过编译技术实现）
	- 每个流水线段设置一个流水寄存器
	- 各个流水段时间尽量相同
	- 流水线具有装入时间和排空时间
- 流水线分类
	- 功能区分（能完成的功能数量）：单功能流水线、多功能流水线
	- 多功能流水线（同一时间内是否能同时执行多种功能）：静态流水线、动态流水线
	- 流水线各个功能段之间是否有反馈信号：线性流水线、非线性流水线（存在反馈回路，某些段会多次通过）
	- 流水线使用的不同级别：部件级流水线、处理机级流水线（指令流水线）、系统级流水线
	- 处理数据：向量流水线、标量流水线
	- 信息流动顺序：同步流水线、异步流水线
- **流水线性能分析
	- 吞吐率：单位时间内流水线执行的任务数量（m段流水线、n个任务）
		- 各段时间相同![[IMG_6EAD915D5060-1.jpeg]]
		- 各段时间不同![[IMG_15AC37E77AD5-1.jpeg]]
		- 总结：制约流水线性能的关键因素就是所有功能段中时间最长的一段，它是流水线的瓶颈
	- 加速比：执行同一批任务，不使用流水线和使用流水线的时间比（大于1）
		- 各段时间相同：![[Pasted image 20230215104218.png]]
		- 各段时间不同：![[Pasted image 20230215104308.png]]
	- 效率：流水线的设备利用率，在时空图上计算![[Pasted image 20230215104407.png]]
		- 各段时间相同![[Pasted image 20230215105138.png]]
		- 各段时间不同，各功能段权重相同![[Pasted image 20230215105152.png]]
		- 各段时间不同，各功能段权重不同（分母不变，分子加权）![[Pasted image 20230215105204.png]]
	- 性价比（PCR）![[Pasted image 20230215105439.png]]
- **相关性分析
	- 分类：资源相关（争用部件）、数据相关、控制相关
	- MIPS基本流水线：每个RISC指令至多五个周期：IF、ID（指令译码并读取寄存器）、EX、MEM、WB
	- 资源相关：
		- 原因：资源重复
		- 处理方法：推后处理
	- 数据相关
		- 先写后读（RAW）：读到还未更新（写入之前）的旧数据
			- **流水线顺序、乱序执行时都可能发生（读周期ID本身就在WB之前）
			- 设置专用路径（定向、旁路）：将一个部件的输出直接送到后面指令的另一个部件作为输入，**一般直接可以在EX、MEM、WB阶段结束后（取决于新数据什么时候就绪），将新数据提前送到下一个指令的ALU作为输入![[Pasted image 20230215113350.png]]
			- 推后处理：无法采用以上方法，流水线停顿等待数据就位
				- 如下图，新数据在MEM阶段才就绪，采用以上方法，下一条指令同样发生RAW![[Pasted image 20230215113625.png]]
				- 通过如下方式，推后处理![[Pasted image 20230215113725.png]]
		- 先读后写（WAR）：读到已经更新（写入之后）的新数据，**只可能在流水线乱序执行时发生
		- 写写（WAW）：先写的覆盖后写的，**只可能在流水线乱序执行时发生
			- 对于WAR和WAW，采用**寄存器换名**技术处理，以下F6与F8分别发生WAW和WAR（方法，冲突的两个采用不同的寄存器，不冲突的可以采用同一个寄存器，具体实现参考Tomasulo算法）![[Pasted image 20230215114124.png]]
		- **Tomasulo算法**（公共数据总线（CDB）法、令牌法）![[Pasted image 20230215143008.png]]
			- 思想：指令**按序发射、乱序执行、乱序完成**，降低RAW影响，同时使用寄存器换名避免WAR、WAW
			- 保留站（实现寄存器换名）结构如下：
				- op：操作类型
				- Vj和Vk：两个源操作数的值
				- Qj和Qk：产生相应源操作数的保留站 **（对于每个源操作数，V字段和Q字段只有一个是有效的）**
				- A：保存load和store操作的存储器地址信息（指令最初的立即数、计算后的有效地址保存于此）
				- Busy：指示该保留站以及相关工作部件是否正在使用
			- 存储设备：
				- load和store缓冲器：每个缓冲器也是一个保留站
				- 浮点寄存器堆：
					- Qi：保存保留站编号，在对应保留站进行的操作，结果会存入这个寄存器。如果Qi为空，说明当前不会有运算结果会存放到该寄存器
			- 指令执行过程：
				- 发射：从操作队列中取指令，若相应保留站空闲（说明没有结构冲突）则发射指令和发送数据，本阶段中进行寄存器换名操作
				- 执行：若源操作数都就绪，则执行运算。否则监视CDB等待源操作数
				- 写回：计算结果送到CDB，进而写回寄存器中（或者被其他保留站读取）
			- 指令格式：
				- 运算指令：rd、rs、rt，其中rs作为操作数j，rt作为操作数k
				- load和store指令：rt、imm、rs，rs为基址寄存器，imm为偏移量，rt存放读出或写入的内容
			- 各个阶段的处理逻辑，以下操作可能在每个周期执行）
				- 发射阶段：需要等待有空闲的保留站（或缓冲器），为当前指令分配该保留站（或缓冲器），编号为r。以下RS为保留站的序列
					- 运算指令：。![[Pasted image 20230215144948.png]]
						- 对于一个操作数（假设为rs，对应Vj），查询对应寄存器的Qi字段
						- 如果Qi字段为空，说明操作数以及就绪，从对应寄存器中读取出来存放在本指令保留站的Vj字段中。同时将Qj字段赋为0
						- 如果Qi字段不为空，说明需要等待其他操作完成，将Qi赋给本保留站的Qj
						- 修改rd寄存器对应的Qi字段，设置为本保留站。同时本保留站设置为忙
					- load和store指令：![[Pasted image 20230215145453.png]]
						- 对于寄存器Rs（存放偏移量，对应Vj和Qj），操作与之前类似
						- 将这个保留站的A字段设置为指令的imm
						- Busy设置为1
						- Load：rt寄存器对应的Qi字段设置为本保留站
						- Store：rt寄存器对应Vk和Qk，操作与之前类似
				- 执行阶段：Load指令需要等待该保留站位于存储器访问队列队首）
					- 运算指令：需要等待Qj和Qk字段全部变为0（说明操作数全部就绪）之后开始计算结果
					- Load指令：![[Pasted image 20230215150133.png]]
						- 首先等待操作数Qj（Rs）就绪，并且本保留站位于存储器访问队列队首。完成A字段的计算。
						- 等待A字段计算完成之后去存储器对应位置读取
					- Store指令：
						- 与Load指令第一步相同，完成A字段计算即可
				- 写回阶段：
					- 运算指令和Load指令：等待执行结束并且CDB空闲![[Pasted image 20230215150703.png]]
						- 对于所有等待本操作数计算结果的寄存器结构（不是保留站），将其Qi字段设置为0，结果存入该寄存器中
						- 对于所有等待本操作数计算结果的保留站，将其Qj或Qk设置为0，值赋给Vj或Vk
						- 释放本保留站，Busy为0
					- Store指令：需要等待执行阶段结束并且Rt寄存器数据就绪，数据写入存储器对应位置，Busy设置为0![[Pasted image 20230215150850.png]]
			- 换名操作：将寄存器和指令的运算内容用一大组"虚拟寄存器名"来代替（也就是保留站），保留站数量大于实际的寄存器数量，用来存放未决的操作数。这个操作过程实现了寄存器换名![[Pasted image 20230216104037.png]]
				- 理解：一个指令发射后，其结果对应的保留站会等待它完成后写回，**后续需要读取这个结果的指令一定会在它执行结束后立刻得到这个结果**。这就解决了读写依赖和写写依赖
	- 控制相关：**条件转移和中断**需要特别处理，无条件转移和子程序调用一般不会出现这个问题
		- 全局相关：会影响程序执行方向的相关（条件转移、中断可能引起）
		- 局部相关：之前的普通数据相关属于其他相关，无条件转移和子程序调用也属于局部相关
		- 条件转移的分析：
			- 前提：k级别流水线执行到条件转移之后会顺序取下一条指令，如果转移成功需要重新取指，相当于浪费了k-1个时钟周期。
			- 假设执行n条指令，其中条件转移所占的比例为p，转移成功的概率为q
				- 执行时间：![[Pasted image 20230216101922.png]]
				- 吞吐率：![[Pasted image 20230216101955.png]]
				- 吞吐率下降的比例：![[Pasted image 20230216102032.png]]
		- **条件转移（以及其可能引起的全局相关）的处理**
			- 条件确定前：
				- 提前形成条件码
					- 在运算部件入口处设置一个比较器，判断两个操作数的符号或指数就可以提前判断结果符号、是否为0等，提前形成条件码
				- 预测：减少预测失败的概率
					- 思想：选择发生概率较高的的分支作为预测方向。**运行但不写回结果**。若正确则继续执行，否则作废，返回实际转移处
					- 后续处理：
						- 分支现场的保护和恢复
							- 方法1：对预测的指令只进行译码和操作数的准备
							- 方法2：执行到运算完成，但不写回结果
							- 方法3：把可能被破坏的原始状态用专门的寄存器保护起来（效率较高）
						- 预测不中时的加速处理：
							- 考虑设置指令目标缓冲栈，分别向转移成功和失败的方向预取指令
					- 静态预测：
						- 通过软件（编译器）预测转移方向，预测的方向一般是固定的（因此是静态），需要编译器把发生概率高的分支安排在预测方向
					- 延迟转移：
						- 在条件转移后设置若干延迟槽，无论是否转移成功都要执行延迟槽中的指令。
						- 编译器需要向延迟槽中放入有用的指令。调度方法有：
							- 从前调度：被调度的指令必须和条件转移指令无关
							- 从目标处调度：保证不成功转移时被调度指令不会产生错误
							- 从失败处调度：保证成功转移时被调度指令不会产生错误
					- 指令取消技术：若实际执行方向和预测的一样，则执行延迟槽中的指令。否则清空延迟槽（将其中的操作转化为空操作）
					- **动态预测**
						- 转移预测缓冲器（Branch History Table BHT）
							- 思想：只依赖本条件转移指令的历史信息（局部信息）进行预测。
							- 实现：设置一个按照条件转移低位进行访问的存储器，其中每个表项对应一个条件转移指令。每次将条件转移是否成功的信息记录在对应表项中。下次依据表的内容判断是否需要转移
							- 1bit 预测缓冲器：每个表项中设置1 bit，记录上次是否转移的信息（1代表转移）![[Pasted image 20230216110802.png]]
							- 2 bit 预测缓冲器：当表项的值大于等于$2^{2-1} = 2$时预测转移，否则预测不转移![[Pasted image 20230216111102.png]]
								- 连续两次预测失败后，才会改变预测方向
								- **预测正确：当预测正确（实际结果与预测结果相同时），发生清零。对于预测的是转移的情况，清零是将状态转化到11，对于预测的是不转移的情况，清零是将状态转化到00**
								- **预测错误：表项的值左移一位，低位记录本次是否转移（本次发生了转移低位记录1，否则低位记录0）
							- n bit 预测缓冲器，每个表项设置n bit，记录之前n次转移信息（变化逻辑与2bit相似，正确则清零，回到全是0或者全是1的状态，错误则左移并记录本次结果）。表项值大于等于$2^{n-1}$时才预测转移
						- 相关转移预测器（也属于BHT） 
							- 思想：依靠已经发生过的其他条件转移的历史信息（全局信息）来预测，预测更加精准
							- （1，1）预测器
								- 有$2^1=2$个预测器，依据前1次其他条件转移的结果来选择使用哪一个预测器（若上次转移了，结果为1，没转移结果为0，可以从两个中选择一个）
								- 每个预测器都是一个1bit 预测器，DFA如之前所示。**每个DFA独立预测，初态相同，转移函数相同。但是每次预测时处在的状态可能不同
							- （m，n）预测器
								- 有$2^m$个预测器，依据前m次其他条件转移的结果来选择使用哪一个预测器（前m次转移结果组成一个m位的2进制数，最后的转移结果位于最低位）
								- 每个预测器是一个n bit预测器
							- 可以发现，之前的2 bit转移预测缓冲器相当于一个（0，2）相关转移预测器（只有$2^0=1$个2 bit转移预测缓冲器可选）
							- （0，2）和（2，2）预测器最常用
							- 实现：使用一个m bit寄存器存放前m次转移的结果，对n bit预测缓冲器的访问**可以用m bit寄存器作为低位，拼接上相关条件转移指令得到
						- 自适应预测器
							- 前两种方法都是基于BHT的预测器，分别基于局部信息和历史信息
							- 思想：**设置两个预测器，分别基于局部信息和全局信息，并且用一个选择器来组合他们**，为每个条件转移指令选择合适的预测器
							- DFA如下：![[Pasted image 20230216114742.png]]
								- a/b，a代表预测器1上次预测是否成功（0失败1成功），b代表预测器2上次预测是否成功
								- 都成功/失败**状态不转移
								- 自己成功、别人失败，采用这种预测器的**优先级升高
								- 自己失败、别人成功，采用这种预测器的**优先级降低
								- 每个预测器存在**两个级别的优先级**。高优先级下无法继续升高，降低一次到低优先级。低优先级下继续降低会转化到另一个预测器的低优先级状态
						- 分支目标缓冲器（Branch Target Buffer BTB）![[Pasted image 20230216120509.png]]
							- 思想：用一个高速缓冲器存放最近**进行了转移**的所有条件转移指令的**条件转移指令地址**和**转移目标指令地址**，转移指令地址全相联存储。执行到条件转移指令时，查表：
								- 在表中：使用表中对应的转移目标指令地址作为下一条执行的指令地址 **（相当于预测发生转移，并直接填写转移目标地址）**
									- 发生了转移：预测正确，继续执行
									- 没有发生转移：预测失败，清楚已取的指令，从转移失败分支重新取指，从BTB中删除这一项
								- 不在表中：
									- 发生了转移：将当前PC值和转移目标地址填入BTB中
									- 没有发生转移：继续执行
							- 延迟分析：BTB表中存在的指令就是预测要转移的指令![[Pasted image 20230216120200.png]]
								- 失败时（转移了表中没有，表中有但没转移）延迟两周期
								- 成功时不延迟
							- 优化：**在BTB中直接存放转移位置处的目标指令**，可以存放一条或多条（提前完成取指）
			- 条件确定后：
				- 停顿（Stall）：预测错误时需要停顿，等待重新取指和执行
		- 中断
			- 问题：确定中断发生时，断点在流水线多条指令中的哪一条上
			- 解决：
				- 不精确断点：
					- 让已经进入流水线的所有指令都执行完成，**断点就是最后进入流水线的那条指令的地址（这条指令也会被执行完成，只是将其地址作为断点）**
					- 例如，下图中不精确断点的地址是i+5![[Pasted image 20230216154025.png]]
					- 优点：需要的硬件支持少，逻辑简单
					- 缺点：中断相应时间长，只能处理IO中断等可以允许较长响应时间的中断
				- 精确断点：
					- 由哪一条指令发出中断请求，就将这条指令的地址作为断点
					- 下图中，精确断点的地址是i![[Pasted image 20230216154210.png]]
					- 优点：能处理的中断类型多，能处理程序性中断、故障中断等
					- 缺点：硬件、控制逻辑更复杂
		- 前瞻执行机制（综合应用）
			- 基础：基于Tomasulo算法、预测执行、保持精确异常
			- 思想：指令**按序发射、乱序执行、乱序完成、按序提交（提交理解为将结果写回，指令结束）**。在**指令提交之前避免任何无法恢复的行为发生**（指令执行之后的结果可以直接为其他指令所用）
			- 部件结构：![[Pasted image 20230216154736.png]]
				- 主要区别：增加了排序缓冲器（Reorder Buffer ROB）
				- 排序缓冲器（ROB）：
					- 作用：在指令执行结束和指令提交之间保存指令的执行结果，按FIFO（指令发射的顺序）存放指令。
						- 指令执行完成：结果送入ROB
						- 指令提交：将ROB顶部的数值写入寄存器中
					- 数据结构：
						- 指令类型：指出指令属于以下哪种类型
							- 分支指令：没有目的结果
							- store：内存地址作为目的
							- 寄存器操作（ALU指令或者load）：寄存器作为目的
						- 目的字段：寄存器号（ALU/load）或内存地址（store）
						- 数值字段：指令提交前的执行结果
						- 就绪字段：该指令是否已经执行结束（结果就绪）
					- 指令执行过程：
						- 发射：从指令队列中取得一条指令，如果**存在相应保留站**并且**ROB存在空闲**，就可以发送指令和数据
						- 执行：当指令所需要的源操作数都准备好，就可以执行运算。否则监视CDB（监视依赖的保留站）等待源操作数
						- 写回结果：运算结果经过CDB送到**ROB**。并且送到任何**等待该结果的保留站中（送入其他保留站不属于无法恢复的行为，可以在提交之前进行）
						- 提交：指令到达ROB头部
							- 预测错误的指令，从ROB中去除该指令，并从正确的分支方向开始运行
							- 预测正确的指令，从ROB中去除该指令，用ROB的值更新相应的内存单元或者寄存器
	- 循环的处理：首先需要理清原本一次循环中实现的逻辑功能
		- 循环所消耗的时钟周期数：一次循环的指令周期数只考虑**发射本循环中所有的指令所需要消耗的时钟周期数**，并且**每次stall，下一条指令延迟一个周期发射**
		- 本节的前提条件：![[Pasted image 20230217110753.png]]
		- 调度技术：
			- 思想：通过调整指令的执行顺序，减少Stall的周期数量，减少一次循环所需要花费的时钟周期数
			- 实现：具体例子具体分析，关键是理清指令之间的逻辑关系，尽可能减少和利用stall周期
			- 例子：![[Pasted image 20230217110818.png]]
			- 总结：
				- 可以微调指令内容，通过改变立即数的方法更改一些指令的次序
				- 在其他指令的stall期间，如果在不引起新的RAW的情况下（新插入的指令与之前前后两条指令都不会发生RAW），可以在之间插入一条新指令的发射
		- 循环展开：展开后的一次循环中进行多次原本的循环
			- 思想：多次复制循环体代码，并调整出口代码
			- 实现：假设原本循环次数为n，一次展开k次循环
				- 第一段循环：循环体与原来相同，进行n mod k次
				- 第二段循环：循环体由原来的循环体展开k次得到，进行n/k次
			- 重点：展开后有些操作可以只进行一次，有些操作还需要多次重复，关键是**如何提取出可以只进行一次的操作，并且保证逻辑正确。**（结合下面的例子理解）
				- 假如每次循环都对某个寄存器的值改变一个定量（比如下面的R1），可以将多次循环的改变合并到一次操作中，更改立即数即可
					- 需要读取原本每次循环中数值都要改变的寄存器，可以尝试通过更改立即数的方式进行（比如使用R1寄存器间接寻址）。
					- 如果不行，则应该在改变数值的操作重复多次，每次改变后再取值，不能一次完成。
				- 对于还多次进行的操作，**假设在原本的循环中，每次值都会改变的寄存器（比如F0、F4），可以在多次进行时每次使用不同的寄存器（F6、F8……）**，这样的好处是方便后续的指令调度，进一步缩短每次循环的平均周期数
			- 计算展开后的周期数（只展开，不进行调度），还是分两部分计算
				- 还需要多次重复的部分，假设原本的循环中消耗的周期数为t1（需要考虑stall，这部分最后的stall也要算在这部分中）
				- 只需要进行一次的部分，假设原本的循环中消耗的周期数为t2（同上）
				- 总时间：$T_k=k.t1 + t2$，平均原本每个周期：$T=T_k/k$
			- 假设展开后还进行了调度，依据调度后的结果具体分析计算
			- 例子：原本的循环体与之前一样
				- 循环展开，一次展开4次循环：![[Pasted image 20230217112451.png]]
					- 消耗的周期数：4\*6 + 4 = 28
					- 平均原本每次循环：28/4=7
				- 循环展开并进行调度：![[Pasted image 20230217114135.png]]
					- 将展开的结果中，需要重复多次执行的部分分解（假设这部分m条指令），依次执行k次重复部分的第1、2、……、m条指令，最后执行可以只执行一次的指令
						- 由于之前更改了寄存器，依次执行重复部分不会发生RAW，可以有效减少STALL周期数（基本不会发生STALL）
						- 若最后只需要执行一次的指令中存在STALL，**可以考虑将重复部分同时执行某一条指令的操作插入到原本的STALL周期中（在不产生新的RAW的前提下，由于更改了寄存器名称，一般不会出现新的RAW）
					- 消耗的周期数：14（没有任何STALL）
					- 平均原本每次循环：14/4=3.5
	- 总结：循环展开和调度
		- 可以用于解决数据相关（RAW、WAW、WAR）
		- 受制于**循环开销的减少程度、代码量大小、寄存器数量
	- 软件流水：循环重组技术
		- 思想：如果（一个循环中）循环体之间是相互独立的，可以把来自不同循环体的指令组合成一个新的循环体，在保证循环体的相关关系的同时提高并行性。![[Pasted image 20230217120052.png]]
		- 例子：还是之前的循环![[Pasted image 20230217121543.png]]
		- 研究循环展开后还是需要多次执行的部分，考虑如何重新组合其中的指令，减少顺序执行时的RAW出现次数（此时不需要像循环展开+调度那样更改寄存器）
			1. 确定重新组合的顺序
			2. 将循环展开m次以进行分析（重复部分有m条指令）
			3. 重新组合，找到新的重复部分，在新的重复部分后添加原本展开后只需要执行一次的部分
			4. 修改立即数使其符合逻辑
		- 优点：软件流水比循环展开产生的代码少
	- 对比：
		- 循环展开：**减少循环开销，计数器更新和分支代码只执行一次
		- 软件流水：**减少循环不能全速执行的次数**（循环体中部分代码作为装入和排空代码只执行一次，剩下的部分经过调整减少RAW的数量）![[Pasted image 20230217122806.png]]
		- 最好能将二者结合使用（先软件流水，再循环展开并调度）
- 多指令发射技术
	- **多发射处理机分类：
		- 超标量处理机
		- 超长指令处理机
		- 超流水线处理机
	- 超标量处理机
		- 工作原理（与标量处理机对比）：
			- 标量处理机：![[Pasted image 20230218112128.png]]
				- 只有一条指令流水线，采用单发射方式
				- 每个周期IF、ID、EX、WB只进行一次（比如可以同时IF和ID两条指令，但不可以同时IF两条指令）
				- 可以流水线也可以不流水线
				- 期望每周期平均一条指令
			- 超标量处理机：![[Pasted image 20230218112143.png]]
				- 必须有两条或以上能同时工作的指令流水线，采用多发射方式（每种操作部件至少有两个）
				- 每个周期IF、ID、EX、MEM、WB可以进行多次
				- 一般采用流水线
				- 期望每个周期平均执行多条指令 
				- **（n流出处理机：最多每周期可流出n条，实际上每周期流出数目不一定是n）
			- 对比：
				- 标量处理机，希望同一类型的指令重复出现，以最大程度地发挥流水线的性能优势。
				- 超标量处理机，希望同一类型的执行尽量不要连续出现，以闭麦了资源冲突。这一特性更适合处理一般的标量程序
		- 时空图（2流出处理机）：![[Pasted image 20230218121614.png]]
		- 定义：一个时钟周期内能够同时发射多条指令的处理机
			- 可以使用编译器静态调度（按序执行）
			- 也可以使用Tomasulo算法一类的动态调度（乱序执行）
		- 先行指令窗口：相当于提前调整指令顺序，以实现乱序发射以减少Stall
			- 能从cache中预取多条指令
			- 对窗口内的指令进行数据相关性的分析和功能部件冲突的检测
			- 至少有一套取指部件和译码部件
		- 调度方法：
			- 顺序发射顺序完成：完成顺序必须与发射顺序相同
			- 顺序发射乱序完成：顺序发射并采用Tomasulo一类的算法乱序完成
			- 乱序发射乱序完成：需要采用先行指令窗口进行调度，乱序发射并结合Tomasulo算法乱序完成
		- 资源冲突：
			- 超标量处理机中，操作部件一般采用流水线结构，否则需要设置多个相同类型的操作部件（资源重复）![[Pasted image 20230225192039.png]]
		- 性能分析：m流出超标量处理机的指令级并行度记作(m,1)，单流水线普通标量处理机记作(1,1)，执行N条指令，每条指令需要k个时钟周期，不考虑冲突和指令相关
			- $T(1,1)=(k+N-1)\Delta t$
			- $T(m,1)=(k+\frac{N-m}{m})\Delta t$
			- 加速比：$S(m,1)=\frac{T(m,1)}{T(1,1)}=\frac{m(k+N-1)}{N+m(k-1)}$
	- 超长指令字处理机（VLIW）
		- 工作原理：![[Pasted image 20230225194829.png]]
			- 编译时：找出指令间潜在的并行性，将多个能并行执行的不相关的操作压缩组合在一起，形成一条有多个操作段的超长指令
			- 运行时：不使用软硬件检测其并行性，直接由这条超长指令控制机器中多个相互独立的功能部件并行操作，每个操作段控制其中一个功能部件，相当于很多条指令同时执行
		- 传统指令和VLIW指令：![[Pasted image 20230225194955.png]]
		- 设计问题：
			- 编译技术：别名分析、循环展开、软件流水、路径调度……
			- 代码膨胀：
				- 为了产生足够的操作填充一条长指令，必须展开多个循环体，增加了代码量
				- 假设指令没有被填满，那么空闲的功能部件在指令译码时仍然会被翻译，并填上无用的指令，增加了代码量
				- 解决：智能译码、代码压缩
			- 二进制代码的兼容性
	- 超流水线处理机：
		- 工作原理：将每个流水段进一步细分，能够在一个时钟周期内分时流出多条指令（每隔1/n个周期，流出一条指令）
		- 时空图：![[Pasted image 20230225202017.png]]
		- 对比：
			- 超标量处理机通过重复设置硬件以提高性能（空间并行性）
			- 超流水线处理机只需要增加少量硬件，通过各硬件的充分重叠工作来提高性能（时间并行性）
- 向量处理机：
	- 定义：具有向量数据表示和向量指令系统的处理机，一般采用流水线结构，有多条流水线并行工作
		- 一条向量指令，处理N个操作数或N对操作
	- 向量处理方式：
		- 例子：计算$D=A*(B+C)$，A、B、C、D都是长度为N的向量
		- 横向处理方式：
			- 定义：向量计算是按行的方式从左到右横向地进行![[Pasted image 20230225203344.png]]
			- 方法：组成循环程序进行处理，会发生较多的数据相关和功能切换，不适用于向量处理机的并行处理![[Pasted image 20230225203442.png]]
		- 纵向处理方式：
			- 定义：向量计算按列的方式从上到下地纵向进行![[Pasted image 20230225203534.png]]
			- 方法：将运算表示成向量指令，数据相关的功能切换较少![[Pasted image 20230225203743.png]]
			- 对处理机结构的要求：**存储器-存储器结构
				- 原向量和目标向量都存放在存储器中，结果也需要写回存储器中
		- 横纵处理方式：
			- 定义：将向量分为若干组，组内使用纵向处理方式，依次处理（横向处理）若干组
			- 方法：对向量进行裁剪，分成若干组以缩小其长度，分组计算![[Pasted image 20230225204421.png]]
			- 对处理机结构的要求：寄存器－寄存器结构
				- 原因：寄存器数量限制，能表示的向量最大长度有限，超过此长度时，需要对向量进行分组处理
				- 设置能快速访问的向量寄存器，源操作数和运算结果都存储其中
	- 以下讨论基于CRAY-1型向量处理机：
		- 四种向量指令类型：![[Pasted image 20230225210037.png]]
		- 特性：
			- 主存访问、元素送到功能部件、结果存入Vi都需要1拍的传送延迟
			- 每个向量寄存器Vi都有连接到全部功能组件的专门总线
			- 每个向量功能部件也有能将结果送回向量寄存器的总线
			- 只要不发生Vi冲突（可以理解为向量之间的数据冲突）和功能部件冲突，各Vi之间和各 功能部件之间都能并行工作
				- Vi冲突和功能部件冲突是两种常见的冲突形式
				- 比如：在没有Vi冲突的前提下，访存指令和向量计算指令可以并行（两条指令同时发射并执行）
		- 向量寄存器V：有512个64位寄存器，分为8组，每组分别是V1～V8，可以存放一个长度最大为64的向量，称为向量寄存器
		- 标量寄存器S：S1～S8，八个64位寄存器
		- 快速暂存器T：在标量寄存器和存储器之间提供缓冲
		- 向量屏蔽寄存器VM：64位，每一位对应向量寄存器的一个单元
	- 关键技术：
		- 资源重复：对于一种功能单元重复设置多个
		- **链接技术（类似于专有数据通路）
			- 基本思想：对有RAW相关的向量指令，可以采用相关专用通道，从一个流水线部件得到的结果直接送入另一个流水线部件的操作寄存器
			- 基本要求：
				- 没有向量寄存器冲突和运算部件冲突
				- 只有当前一条指令的第一个结果分量送入结果向量寄存器的那一个时钟周期才可以链接
				- **当一条向量指令的两个源操作数分别是两条先行指令的结果时，要求：
					- **先行的两条指令产生结果的时间必须相等
					- **先行的两条指令的向量长度必须相等
			- 例子：已知访存指令和浮点加指令需要6个时钟周期、浮点乘需要7个时钟周期，整数加需要3个时钟周期![[Pasted image 20230225210825.png]]
				- 以上例子需要用三条向量指令完成，其中1、2两条之间不存在相关，可以并行，3与1、2存在Vi相关![[Pasted image 20230225211731.png]]
				- 链接示意图如下：直接将存放值的寄存器，提供值、需要使用值的存储器或者运算部件连接起来即可![[Pasted image 20230225213037.png]]
				- 全部串行执行，执行时间如下：![[Pasted image 20230225211827.png]]
				- 前两条并行，第三条指令串行执行：![[Pasted image 20230225213528.png]]
				- 前两条并行，与第三条指令链接执行：![[Pasted image 20230225213619.png]]
		- 向量循环/分段开采技术：当向量的长度大于向量寄存器的长度时，采用循环处理长向量
	- **性能评价指标（重点是了解含义，计算看一下就行）：
		- 向量指令处理时间$T_{vp}$
			- 一条向量指令的处理时间，处理的向量长度为n：![[Pasted image 20230225220541.png]]
			- 一组向量指令的处理时间：
				- 因素：
					- 向量长度
					- 向量之间是否链接
					- 部件冲突和功能冲突是否存在
				- 编队：把几条能在同一个时钟周期内一起开始执行的向量指令集合称为一个编队
					- 同一个编队中的向量指令之间一定不存在流水向量功能部件的冲突和数据的冲突
				- 例子：![[Pasted image 20230225215805.png]]
				- 向量长度<=向量寄存器长度（不需要分段开采）：
					- $T_n=\sum\limits^{T_{chime}}\limits_{i=1}[T_{start}+(n-1)T_c]$ 
					- 就是分别求每个编队的执行时间并求和，$T_{start }= s + e$（启动开销）
				- 向量长度>向量寄存器长度（需要分段开采）：![[Pasted image 20230225221634.png]]
					- **$T_{strat}$：所有指令的启动时间之和
					- $T_{loop}$：执行标量代码的开销，常数，一般是15
					- n：向量长度
					- $T_{chime}$：分组数
		- 最大性能R：$R_∞$ 表示当向量长度为无穷大时，向量处理机的最高性能，也称为峰值性能（每秒能处理的指令数目）。![[Pasted image 20230225222437.png]]
			- 浮点运算次数：为浮点向量指令数乘上向量长度
			- 执行所需的时钟周期数使用上面的一组向量的时间计算
		- 半性能向量长度$n_{1/2}$：向量处理机的运行性能 达到其峰值性能的一半时所必须满足的向量长度
			- 带入最大性能R的算式中解出即可
		- 向量长度临界值$n_v$：对于某一计算任务而言， 向量方式的处理速度**优于标量串行方式处理速度**时所需的最小向量长度
			- 方法：
				- 顺序执行的时间：所有向量指令启动时间之和（之前的例子里是49），加上循环建立的开销，乘上向量长度
				- 向量处理时间，使用一批向量运算的执行时间公式算出来（假设不需要循环开采）
				- 顺序执行时间应该大于向量处理时间
- 存储系统：
	- 定义：多个速度、容量、价格各不相同的存储器用软件、硬件、软硬件结合的方法连接起来成为一个系统。该系统对程序员透明
		- 透明：
			- 程序员看来只有一个存储器
			- 速度接近于最快的那个存储器
			- 单位容量价格接近于最便宜的那个存储器
			- 容量接近于最大的那一个存储器
	- **如何提高存储器的频宽：![[Pasted image 20230226180957.png]]
	- 常用的存储系统：
		- 虚拟存储系统
			- 原理：主存储器和磁盘存储器构成
			- 特点：使用软件硬件结合的方式调度，对应用程序是透明的，对系统程序不是透明的
		- Cache存储系统
			- 原理：由Cache和主存储器构成
			- 特点：全部使用硬件调度，对应用程序和系统程序都是透明的
	- 存储系统性能评价：以两个存储器组成的存储系统为例，M1为容量更小但速度更快的存储器![[Pasted image 20230226152113.png]]
		- 存储容量：接近于最大的那个存储器的容量（接近于S2）
		- 存储价格（单位容量价格）：加权平均$$C=\frac{S_1.C_1+S_2.C_2}{S_1+S_2}$$
		- 存储速度：
			- 命中率H：访问M1的概率，$N_1$和$N_2$分别是M1和M2的访问次数$$H=\frac{N_1}{N_1+N_2}$$
			- 访问时间T：$$T=H.T_1+(1-H).T_2$$
			- 访问效率：$$e=\frac{T_1}{T}=\frac{1}{H+(1-H).\frac{T_2}{T_1}}=f(H,\frac{T_2}{T_1})$$
			- 提升访问效率的方法：
				- 提高命中率H（采用预取技术）$$H'=\frac{H+n-1}{n}$$n是数据块大小和数据重复使用次数的乘积
				- 减小两个存储器之间的访问速度差距（减小T2/T1）
	- 并行存储器：
		- 并行访问存储器：
			- 思想：增加存储器的字长，例如把m字w位存储器改成m/n字n* w位存储器![[Pasted image 20230226154558.png]]
			- 特点：
				- 优点：实现简单容易
				- 缺点：访问的冲突大
		- 交叉访问存储器
			- 地址码高位交叉：高位用于选择存储器，低位访问存储器内地址![[Pasted image 20230226154821.png]]
			- 地址码低位交叉：低位用于选择存储器，高位访问存储器内地址![[Pasted image 20230226154923.png]]
		- 问题：存在访问冲突，程序中的转移指令和数据的随机性会导致访问冲突的出现
	- 虚拟存储系统
		- 基本概念：
			- 三个地址空间：虚拟地址空间、主存地址空间、辅存地址空间（大容量存储器等）
			- 三个地址：虚拟地址、主存地址、辅存地址
			- 地址映像：将虚拟地址空间映射到主存地址空间
			- 地址变换：在程序运行时，将虚地址变换成主存地址（内部地址变换）或者辅存地址（外部地址变换）
		- 段式虚拟存储器
			- 地址映像：![[Pasted image 20230226155844.png]]
			- 地址变换：![[Pasted image 20230226155926.png]]
				- 首先用用户号查段表基址寄存器，查到这个用户的段表起始地址
				- 使用段号，在段表中查到主存中的起始地址
				- 主存起始地址+段内偏移量得到主存地址
			- 特点：
				- 优点：程序模块化性能好，容易调度
				- 缺点：地址变化花费时间长、主存储器利用率低，管理辅存较为困难
		- 页式虚拟存储器
			- 地址映像：![[Pasted image 20230226160245.png]]
			- 地址变换：与段式方法类似，只是页的长度固定![[Pasted image 20230226160343.png]]
			- 特点：
				- 优点：主存利用率高、地址变化速度快
				- 缺点：页表消耗较多存储空间、程序模块化性能欠佳
		- 段页式虚拟存储器
			- 地址映像：每段长度不一样，但是都是页长度的整倍数（向上取整）![[Pasted image 20230226160541.png]]
			- 地址变化：![[Pasted image 20230226160613.png]]
				- 用户号获取段表地址
				- 段表中，使用段号查询到页表地址
				- 页表中，用虚页号查到实页号，加上页内偏移得到实地址
			- 特点：兼具段页式方式的优点
		- 加快内部地址变换速度的方法：以页式虚拟存储器为例
			- 目录表：
				- 基本思想：压缩页表的存储容量，用一个小容量高速存储器存放页表，从而加快页表查表速度
					- 页表压缩：页表中只保存已经装入主存的那些页
				- 实现：![[Pasted image 20230226161118.png]]
					- 目录表按内容访问，需要遍历整张表
				- 特点：
					- 优点：查表快
					- 缺点：可拓展性差，主存容量增加，目录表造价高、速度降低
			- 快慢表：
				- 基本思想：页表分为块表和慢表，快表（TLB）由小容量高速硬件实现，存放最近用到的页表信息。快表中查不到再查慢表
				- 实现：![[Pasted image 20230226161427.png]]
			- 散列函数：
				- 基本思想：将快表的按内容相联访问变成按地址访问，使用哈希函数将多用户虚页号转化为快表地址
				- 实现（就是对U，P哈希了一下）：![[Pasted image 20230226161728.png]]
		- 页面置换算法：
			- 随机置换（RAND）算法
			- 先进先出（FIFO）算法：
				- 特点：容易实现，利用了历史信息，但没有反应程序局部性
			- 近期最少使用算法（LFU）
				- 特点：实现困难，利用了局部信息和历史信息
			- 最久没有使用算法（LRU）
				- 特点：实现较为容易，利用了历史和局部信息
			- 最优替换算法（OPT）
				- 特点：性能最优，理想算法无法实现
			- **堆栈型算法**：包括LFU、LRU、OPT，FIFO不是
	- Cache存储系统：
		- 与虚拟存储系统对比：![[Pasted image 20230226162507.png]]
		- 工作原理：![[Pasted image 20230226163251.png]]
		- 地址映像和变换方法：
			- 基本概念：
				- 地址映像：将主存的的数据按某种规则放入cache中，建立主存地址和cache地址之间的对应关系
				- 地址变换：实际运行过程中，CPU给出主存地址，需要将主存地址变化为Cache地址
			- 直接映像：相当于一组只有一块的组相联
				- 方法：![[Pasted image 20230226163946.png]]
				- 地址变化：![[Pasted image 20230226164207.png]]
					- cache字块地址，查询cache这一块的主存标记号
					- 和给出主存地址的主存标记号对比，判断是否命中
					- 如果命中，使用块内地址对cache块进行访问
				- 特点：
					- 优点：实现方便、速度快
					- 缺点：cache的块冲突率很高，cache空间利用率低
			- 全相联映像：相当于一组的大小等于整个cache大小的组相联
				- 方法：![[Pasted image 20230226164635.png]]
				- 地址变换：![[Pasted image 20230226164750.png]]
					- 查询所有cache块，直到找到主存字块标记号等于本指令的标记号的cache块，之后使用块内地址访问这个块
					- cache地址：块号和块内字号
				- 特点：
					- 优点：cache块冲突率低、空间利用率高
					- 缺点：速度慢，实现较为困难
			- 组相联映像：以上两种方案的折中，最常用
				- 实现：组内全相联，组与组之间直接相联![[Pasted image 20230226165207.png]]
					- $2^{c-r}$：Cache中的组的数量，一组中有$2^r$块
					- 主存字块标记：在主存储器中，有$2^{t+r}$个字块可能会被映射到同一组，使用不同的标记区分他们
					- 首先使用组地址找到组号（在全相联中，组号只可能是1）
					- 在组号中，找到主存块标记和本地址的主存块标记相同的cache块，命中（在直接相联中，一组中只有一块，直接比较即可，在全相联中，需要和cache中所有字块比较）
					- cache地址：分为组号、组内块号、块内字号
				- 相联度：一组有多少个个块，与之相关的是**冲突缺失
		- Cache替换算法：
			- 基本概念：
				- 特点：直接相联基本不需要替换算法（命中就不换，不命中就换），全相联的替换算法最为复杂
					- 与虚拟存储器替换算法对比：Cache替换算法全部由硬件实现，虚拟存储器替换算法主要由软件实现
			- 轮换法：
				- 本质是一个FIFO算法，常用于组相联映像方式中
				- 每块一个计数器
					- 长度：等于一组内的块号（比如一组内有4块，长度为2）
					- 装入或置换时：被装入块的计数器置0，同组其他块计数器加一
					- 命中时：不发生改变
					- 需要置换时，同组中计数器值最大的块被置换
					- 例子：![[Pasted image 20230226174447.png]]
				- 每组一个计数器
					- 长度：等于一组内的块号，初始为0
					- 装入时：计数器不变
					- 替换时：计数器对应的块被替换，计数器加一，选择计数器对应的块置换
			- LRU算法：
				- 每块一个计数器
					- 长度等于一组内的块号（与之前相同）
					- 装入或置换：被装入或置换块的计数器清0，同组其他块计数器加一（与每块一个计数器的轮换法相同）
					- 命中时：
						- 同组内比命中块计数器值小的块，计数器加一（相当于被替换的优先级提高），其他块计数器值不变
						- 命中块的计数器清零
					- 需要置换时：同组内计数器最大的块被置换（与之前相同）
				- 比较对法
					- 使用硬件逻辑实现的LRU算法
					- 使用一个两态触发器记录两个块之间被访问的先后顺序，多个块可以用多个两态触发器实现
					- 例子：![[Pasted image 20230226180615.png]]
				- 堆栈法：
					- 用栈记录一组内各个块被访问的先后次序，栈底的时最久没被访问过的块
		- Cache性能评价：
			- CPU执行时间：![[Pasted image 20230226183918.png]]
				- 每条指令平均访存次数：
					- 普通指令：访存一次（取指）
					- Load/Store：访存两次 
			- 平均存储器访问时间（AMAT）：$$AMAT=H.T_{cache}+(1-H).T_{mem}$$![[Pasted image 20230226184000.png]]
				- 缺失代价：访问主存时间减访问cache时间，**注意：失效开销一般是访问主存的时间减去访问cache的时间，实际的时间应该是访问cache的时间加上失效开销
				- 命中时间：访问cache时间
				- 例子：![[Pasted image 20230226185821.png]]
	- 提升Cache性能方法：
		- 降低缺失代价
			- 多级cache
				- 性能分析：![[Pasted image 20230226210000.png]]
					- 注意：第二级Cache缺失率是在第一级cache缺失的前提上计算的，也就是用第二级的缺失次数除以**第一级的缺失次数
					- 缺失代价是访问L2，使用L2的AMAT计算
					- 全局缺失率：本级cache缺失率乘上更高级（更靠近CPU）的cache缺失率，评价二级cache时，应该使用全局缺失率
				- 设计上，二级cache应该：
					- 容量远大于第一级cache
					- 采用更高的相联度
					- 采用和第一级相比更大的块
				- 例子：![[Pasted image 20230226210359.png]]
			- 请求字处理技术：
				- 思想：CPU同一时刻只需要块中的一个字，因此不需要等块全部装入就可以将所需要的字送出
				- 方法：
					- 尽早重启动：正常顺序获取字，只要请求字一到达就将其送入CPU，CPU继续运行
					- 请求字优先：先向存储器请求缺失的字，一旦到达就送给CPU，CPU继续执行，同时装入块中的其他字
				- 局限性：受块大小的影响较大
			- 牺牲者Cache：
				- 思想：添加一个小的、全相联的Cache，这个牺牲者Cache中只包含因为冲突被换出的块，在缺失发生时，先检查牺牲者Cache，如果有想要的数据就牺牲块和cache块互换
		- 降低缺失率
			- **导致缺失的原因：
				- 强制缺失（首次访问缺失、冷启动缺失）：第一次访问的块一定不在cache中
					- 预取方法，减少强制缺失
				- 容量缺失：cache无法容纳一个程序持续执行所需要的所有的块
					- 增加容量
				- 冲突缺失：采用组相联，如果太多块被映射到同一组，可能会有cache块被换出，之后又访问这个块时出现
					- 相联度高（一个块中容量大），冲突缺失少
			- 增加块的大小：32/64B最通用
				- 先降低后升高cache的缺失率（利用了局部性原理）
				- 增加缺失代价
				- 越快的存储器，块应该更大：低延迟、高带宽存储器块要大一些（缺失代价增加少）
			- 增加相联度：
				- 减少冲突缺失
				- 增加命中时间
			- 编译优化：
				- 思想：重新规划代码，增加局部性
				- 内外循环变换：增加空间局部性
				- 循环融合：增加时间局部性![[Pasted image 20230226212503.png]]
		- 降低命中时间
			- 采用小而简单的cache
			- 虚拟cache：![[Pasted image 20230226212636.png]]
				- 并非全部采用虚拟cache
- 互连网络：
	- 基本概念
		- 定义：
			- 一种由开关元件按照一定的拓扑结构和控制方式构成的网络，用于实现计算机系统内部多个处理机之间的相互连接
		- 互联网络的表示：![[Pasted image 20230226225513.png]]
	- 常用互联函数：
		- 恒等置换：![[Pasted image 20230226225650.png]]
		- 交换置换：输入端的二进制地址编号的最后一位取反![[Pasted image 20230226230035.png]]
		- 方体置换：输入的二进制地址长度为n，就有n种方体置换Cn，其中C0等价于交换置换![[Pasted image 20230226230136.png]]
			- 主要用于超立方体互联网中，因此页称为超立方体函数
		- 均匀洗牌置换（Shuffle）![[Pasted image 20230226230244.png]]
			- 逆洗牌：全部循环右移一位
			- 应用：构成omega和逆omega网络
		- 蝶式置换![[Pasted image 20230226230503.png]]
			- 应用：构成方体多集网络
		- 位序颠倒置换![[Pasted image 20230226230647.png]]
		- 加减2i置换：本质上是一种移数置换![[Pasted image 20230226230812.png]]
	- 互联网络的种类
		- 静态互联网络：在各个节点之间有固定的连接通路，在运行过程中不能改变的网络结构
			- 线性阵列：最简单、实现成本低、网络延迟大
			- 环形：![[Pasted image 20230226234914.png]]
			- 树形
			- 网格型
			- 超立方体
		- 动态互联网络：节点之间的连接可以重新配置
			- 总线网络：![[Pasted image 20230226235256.png]]
			- 交叉开关网络：一组纵横开关阵列构成多总线![[Pasted image 20230226235508.png]]
			- Delta网络：![[Pasted image 20230226235530.png]]
		- 多级网络：
			- 基本思想：多级互连网络用若干个较小规模的开关模块组成开关级，开关级之间有固定连接的级间连接，通过控制信号改变开关模块的输入端和输出端之间的连接状态
			- 二元开关：![[Pasted image 20230226235904.png]]
			- 控制方式：
				- 级控制：同一级开关模块使用同一个控制信号控制，只能同时处于同一种状态
				- 单元级控制：每个开关模块都有一个独立的控制信号，可各自处于不同的状态
			- STARAN网络：
				- 输入是N，第一级是恒等置换，后面都是逆洗牌置换，每个级别有N/2个开关![[Pasted image 20230227003933.png]]
				- 采用级控制信号（交换网络）的STARAN网络，每一级的所有开关采用相同的信号控制，0表示直通，1表示交换![[Pasted image 20230227004133.png]]
				- 采用部分级控制：移数网络
			- 间接二进制n方体网络：![[Pasted image 20230227005129.png]]
				- 结构：![[Pasted image 20230227005147.png]]
			- 第i级交换开关属于交换状态时，实现的是cube_i网络，因此STARAN和间接二进制n方体网络是多级立方体网络
			- Omega网络：和STARAN网络类似，但采用均匀洗牌（循环左移），且开关采用单元控制方式![[Pasted image 20230227005330.png]]
				- 开关为二功能开关，且采用级控制，omega网络是STARAN交换网络的逆网络
				- 开关为二功能开关，且部分级控制，omega网络是STARAN移数网络的逆网络
			- 阻塞型网络：
				- 定义：![[Pasted image 20230227005644.png]]
				- 例子：![[Pasted image 20230227005700.png]]
				- 前面介绍的三种网络都是阻塞式网络
	- 消息传递机制
		- 基本概念：
			- 消息格式：![[Pasted image 20230227010920.png]]
		- 寻径的目的：要将一个包从一个部件发送到另一个部件，要找到一条通路
		- 线路交换寻径：先建立一条从源节点到目的节点的物理通路，再传递消息
		- 存储转发寻径：信息流的单位是包，每个节点有一个包缓冲区，包从源节点经过中间节点到达目的节点
		- 虚拟直通寻径：接收到用作寻径的包头部时，开始路由选择
		- 虫蚀寻径：![[Pasted image 20230227011004.png]]
			- 原理：先派出一个片，寻找通路，后面所有的片跟着前面的片
			- 走不动就在对应的片缓冲区中等待
			- 传输时延：片的长度除以贷款，乘上经过的节点数，加上包的长度除以带宽![[Pasted image 20230227143446.png]]
		- 寻径算法：
			- X-Y寻径：![[Pasted image 20230227012243.png]]
			- E立方体寻径：![[Pasted image 20230227012319.png]]
		- 多计算机网络会出现四种通信模式：单播（一对一）、选播（一对多）、广播（一对全体）、会议（多对多）
